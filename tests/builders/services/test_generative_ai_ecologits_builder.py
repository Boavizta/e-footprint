import unittest
from unittest.mock import Mock, patch
from efootprint.constants.units import u
from efootprint.abstract_modeling_classes.source_objects import SourceValue
from efootprint.core.hardware.servers.server_base_class import Server
from efootprint.builders.hardware.gpu_server_builder import GPUServerBuilder
from efootprint.builders.services.generative_ai_ecologits import GenAIModel

class TestGenAIModel(unittest.TestCase):
    def setUp(self):
        self.mock_server = Mock(spec=Server)
        self.mock_server.contextual_modeling_obj_containers = []
        self.mock_server.name = "Test Server"
        self.mock_server.generated_by = Mock(spec=GPUServerBuilder)
        self.mock_server.generated_by.contextual_modeling_obj_containers = []
        self.mock_server.updated_after_generation = False
        self.mock_server.generated_by.ram_per_gpu = SourceValue(80 * u.GB)
        self.mock_server.generated_by.nb_of_cpu_cores_per_gpu = SourceValue(1 * u.core)

        self.model_name = "open-mistral-7b"
        self.provider = "mistralai"
        self.genai_model = GenAIModel(
            name="Test GenAI", provider=self.provider, model_name=self.model_name, server=self.mock_server)

    def test_initialization(self):
        """Test that the model initializes correctly."""
        self.assertEqual(self.genai_model.provider.value, self.provider)
        self.assertEqual(self.genai_model.model_name.value, self.model_name)
        self.assertEqual(self.genai_model.server, self.mock_server)
        self.assertEqual(self.genai_model.nb_of_bits_per_parameter.value, 16 * u.dimensionless)

    def test_initialization_fails_if_server_not_generated_by_gpu_server_builder(self):
        """Test that the model initialization fails if the server is not generated by a GPU server builder."""
        mock_server = Mock(spec=Server)
        mock_server.contextual_modeling_obj_containers = []
        mock_server.name = "Test Server"
        mock_server.generated_by = None
        with self.assertRaises(PermissionError):
            GenAIModel(name="Test GenAI", provider=self.provider, model_name=self.model_name, server=mock_server)

    def test_initialization_fails_if_gpu_server_has_been_updated(self):
        """Test that the model initialization fails if the GPU server has been updated after generation."""
        mock_server = Mock(spec=Server)
        mock_server.contextual_modeling_obj_containers = []
        mock_server.name = "Test Server"
        mock_server.generated_by = Mock(spec=GPUServerBuilder)
        mock_server.generated_by.contextual_modeling_obj_containers = []
        mock_server.updated_after_generation = True
        with self.assertRaises(PermissionError):
            GenAIModel(name="Test GenAI", provider=self.provider, model_name=self.model_name, server=mock_server)

    def test_update_active_params(self):
        """Test updating active parameters."""
        mock_model = Mock()
        mock_model.architecture.parameters = 2
        with patch("efootprint.builders.services.generative_ai_ecologits.models.find_model",
                   return_value=mock_model):
            self.genai_model.update_active_params()
            self.assertEqual(self.genai_model.active_params.value, 2e9 * u.dimensionless)

    def test_update_total_params(self):
        """Test updating total parameters."""
        mock_model = Mock()
        mock_model.architecture.parameters = 5
        with patch("efootprint.builders.services.generative_ai_ecologits.models.find_model",
                   return_value=mock_model):
            self.genai_model.update_total_params()
            self.assertEqual(self.genai_model.total_params.value, 5e9 * u.dimensionless)

    def test_update_base_ram_consumption(self):
        """Test updating base RAM consumption."""
        self.genai_model.total_params = SourceValue(5e9 * u.dimensionless)
        self.genai_model.update_base_ram_consumption()
        expected_ram = 1.2 * 5e9 * 16 * u.dimensionless
        self.assertEqual(expected_ram.to(u.GB), self.genai_model.base_ram_consumption.value)

    def test_update_nb_of_required_gpus_during_inference(self):
        """Test updating the number of required GPUs during inference."""
        self.genai_model.active_params = SourceValue(2e9 * u.dimensionless)
        self.genai_model.update_nb_of_required_gpus_during_inference()
        expected_gpus = (1.2 * 2e9 * 16 * u.dimensionless / (80 * u.GB)).to(u.dimensionless)
        self.assertEqual(expected_gpus, self.genai_model.nb_of_required_gpus_during_inference.value)

    def test_generate_job(self):
        """Test generating a job."""
        output_token_count = SourceValue(1000 * u.dimensionless)
        with patch("efootprint.builders.services.generative_ai_ecologits.Job") as mock_job:
            self.genai_model.active_params = SourceValue(2e9 * u.dimensionless)
            self.genai_model.generate_job(output_token_count)
            gpu_latency = SourceValue(1000 * ((8.02e-4 * 1e-9 * u.s) * 2e9 + 2.23e-2 * u.s))
            mock_job.assert_called_once_with(
                f"request to {self.model_name} installed on {self.mock_server.name}",
                self.mock_server,
                data_upload=SourceValue(100 * u.kB),
                data_stored=SourceValue(100 * u.kB + 24000 * u.dimensionless),
                data_download=SourceValue(100 * u.kB + 24000 * u.dimensionless),
                request_duration=gpu_latency,
                cpu_needed=(self.genai_model.nb_of_required_gpus_during_inference
                            * self.mock_server.generated_by.nb_of_cpu_cores_per_gpu),
                ram_needed=SourceValue(0 * u.GB)
            )

    def test_initialization_for_all_possible_list_input_values(self):
        for provider in GenAIModel.list_values()["provider"]:
            for model_name in GenAIModel.conditional_list_values()["model_name"]["conditional_list_values"][provider]:
                model = GenAIModel(name="Test GenAI", provider=provider, model_name=model_name, server=self.mock_server)


if __name__ == "__main__":
    unittest.main()
