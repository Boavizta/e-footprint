<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork_d106bb {
                 width: 1800px;
                 height: 900px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork_d106bb" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork_d106bb');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": null, "id": "on premise GPU server hour by hour compute need", "label": "on premise GPU\nserver hour by hour\ncompute need", "shape": "dot", "size": 15, "title": "on premise GPU server hour by hour compute need\n=\nHourly Manually defined GPU job average occurrences across usage patterns * gpus\nneeded on server on premise GPU server to process Manually defined GPU job from\ne-footprint hypothesis + no value + Hourly Generative AI model job average\noccurrences across usage patterns * Generative AI model job nb of required GPUs\nduring inference\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\nlast 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] * 1.0 gpu + no\nvalue + 26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00\nin dimensionless:\nfirst 10 vals [0.03, 0.03, 0.02, 0.05, 0.04, 0.05, 0.06, 0.06, 0.03, 0.02],\nlast 10 vals [0.05, 0.02, 0.01, 0.07, 0.03, 0.05, 0.07, 0.02, 0.03, 0.06] *\n0.2199999988079071 gpu\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in gpu:\nfirst 10 vals [0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.02, 0.02, 0.01, 0.01],\nlast 10 vals [0.01, 0.01, 0.0, 0.02, 0.01, 0.01, 0.02, 0.0, 0.01, 0.02]", "x": 0.0, "y": 900}, {"color": null, "id": "Hourly Manually defined GPU job average occurrences across usage patterns", "label": "Hourly Manually\ndefined GPU job\naverage occurrences\nacross usage\npatterns", "shape": "dot", "size": 15, "title": "Hourly Manually defined GPU job average occurrences across usage patterns\n=\nAverage hourly Manually defined GPU job occurrences in usage pattern + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\nlast 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\nlast 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]", "x": -337.5, "y": 750}, {"color": null, "id": "Average hourly Manually defined GPU job occurrences in usage pattern", "label": "Average hourly\nManually defined GPU\njob occurrences in\nusage pattern", "shape": "dot", "size": 15, "title": "Average hourly Manually defined GPU job occurrences in usage pattern\n=\nHourly Manually defined GPU job occurrences in usage pattern hourly occurrences\naverage Request duration of Manually defined GPU job from e-footprint hypothesis\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0] hourly\noccurrences average 1.0 second\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\nlast 10 vals [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]", "x": -375.0, "y": 600}, {"color": null, "id": "Hourly Manually defined GPU job occurrences in usage pattern", "label": "Hourly Manually\ndefined GPU job\noccurrences in usage\npattern", "shape": "dot", "size": 15, "title": "Hourly Manually defined GPU job occurrences in usage pattern\n=\nusage pattern UTC shifted by no value + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0] shifted by no\nvalue + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0]", "x": -375.0, "y": 450}, {"color": null, "id": "usage pattern UTC", "label": "usage pattern UTC", "shape": "dot", "size": 15, "title": "usage pattern UTC\n=\nusage pattern hourly nb of visits from e-footprint hypothesis converted to UTC\nfrom devices country timezone from user data\n=\n26298 values from 2025-01-01 00:00:00 to 2028-01-01 18:00:00 in dimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0] converted to UTC\nfrom Europe/Paris\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0]", "x": -360.0, "y": 300}, {"color": "darkred", "id": "usage pattern hourly nb of visits from e-footprint hypothesis", "label": "usage pattern hourly\nnb of visits from\ne-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "usage pattern hourly nb of visits from e-footprint hypothesis = 26298 values\nfrom 2025-01-01 00:00:00 to 2028-01-01 18:00:00 in dimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0]", "x": -337.5, "y": 150}, {"color": "gold", "id": "devices country timezone from user data", "label": "devices country\ntimezone from user\ndata", "shape": "dot", "size": 15, "title": "devices country timezone from user data = Europe/Paris", "x": -112.5, "y": 150}, {"color": "darkred", "id": "Request duration of Manually defined GPU job from e-footprint hypothesis", "label": "Request duration of\nManually defined GPU\njob from e-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "Request duration of Manually defined GPU job from e-footprint hypothesis = 1.0\nsecond", "x": -225.0, "y": 450}, {"color": "darkred", "id": "gpus needed on server on premise GPU server to process Manually defined GPU job from e-footprint hypothesis", "label": "gpus needed on\nserver on premise\nGPU server to\nprocess Manually\ndefined GPU job from\ne-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "gpus needed on server on premise GPU server to process Manually defined GPU job\nfrom e-footprint hypothesis = 1.0 gpu", "x": -112.5, "y": 750}, {"color": null, "id": "Hourly Generative AI model job average occurrences across usage patterns", "label": "Hourly Generative AI\nmodel job average\noccurrences across\nusage patterns", "shape": "dot", "size": 15, "title": "Hourly Generative AI model job average occurrences across usage patterns\n=\nAverage hourly Generative AI model job occurrences in usage pattern + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.03, 0.03, 0.02, 0.05, 0.04, 0.05, 0.06, 0.06, 0.03, 0.02],\nlast 10 vals [0.05, 0.02, 0.01, 0.07, 0.03, 0.05, 0.07, 0.02, 0.03, 0.06] + no\nvalue\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.03, 0.03, 0.02, 0.05, 0.04, 0.05, 0.06, 0.06, 0.03, 0.02],\nlast 10 vals [0.05, 0.02, 0.01, 0.07, 0.03, 0.05, 0.07, 0.02, 0.03, 0.06]", "x": 112.5, "y": 750}, {"color": null, "id": "Average hourly Generative AI model job occurrences in usage pattern", "label": "Average hourly\nGenerative AI model\njob occurrences in\nusage pattern", "shape": "dot", "size": 15, "title": "Average hourly Generative AI model job occurrences in usage pattern\n=\nHourly Generative AI model job occurrences in usage pattern hourly occurrences\naverage Generative AI model job request duration\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0] hourly\noccurrences average 28154599424.0 nanosecond\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [0.03, 0.03, 0.02, 0.05, 0.04, 0.05, 0.06, 0.06, 0.03, 0.02],\nlast 10 vals [0.05, 0.02, 0.01, 0.07, 0.03, 0.05, 0.07, 0.02, 0.03, 0.06]", "x": -225.0, "y": 600}, {"color": null, "id": "Hourly Generative AI model job occurrences in usage pattern", "label": "Hourly Generative AI\nmodel job\noccurrences in usage\npattern", "shape": "dot", "size": 15, "title": "Hourly Generative AI model job occurrences in usage pattern\n=\nusage pattern UTC shifted by no value + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0] shifted by no\nvalue + no value\n=\n26298 values from 2024-12-31 23:00:00+00:00 to 2028-01-01 17:00:00+00:00 in\ndimensionless:\nfirst 10 vals [4.0, 4.0, 2.0, 6.0, 5.0, 6.0, 8.0, 8.0, 4.0, 3.0],\nlast 10 vals [7.0, 3.0, 1.0, 9.0, 4.0, 7.0, 9.0, 2.0, 4.0, 8.0]", "x": -75.0, "y": 450}, {"color": null, "id": "Generative AI model job request duration", "label": "Generative AI model\njob request duration", "shape": "dot", "size": 15, "title": "Generative AI model job request duration\n=\nGenerative AI model job output token count from e-footprint hypothesis * (GPU\nlatency per active parameter and output token from Ecologits * open-mistral-7b\nfrom mistralai nb of active parameters from Ecologits + Base GPU latency per\noutput_token from Ecologits)\n=\n1000.0 dimensionless * (0.0 nanosecond * 7299999744.0 dimensionless +\n0.019999999552965164 second)\n=\n28154599424.0 nanosecond", "x": 75.0, "y": 450}, {"color": "darkred", "id": "Generative AI model job output token count from e-footprint hypothesis", "label": "Generative AI model\njob output token\ncount from\ne-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "Generative AI model job output token count from e-footprint hypothesis = 1000.0\ndimensionless", "x": -180.0, "y": 300}, {"color": "darkred", "id": "GPU latency per active parameter and output token from Ecologits", "label": "GPU latency per\nactive parameter and\noutput token from\nEcologits", "shape": "dot", "size": 15, "title": "GPU latency per active parameter and output token from Ecologits = 0.0\nnanosecond", "x": 0.0, "y": 300}, {"color": null, "id": "open-mistral-7b from mistralai nb of active parameters from Ecologits", "label": "open-mistral-7b from\nmistralai nb of\nactive parameters\nfrom Ecologits", "shape": "dot", "size": 15, "title": "open-mistral-7b from mistralai nb of active parameters from Ecologits\n=\nmistralai from e-footprint hypothesis query EcoLogits data with mistralai model\nused from e-footprint hypothesis\n=\nmistralai query EcoLogits data with open-mistral-7b\n=\n7299999744.0 dimensionless", "x": 180.0, "y": 300}, {"color": "darkred", "id": "mistralai from e-footprint hypothesis", "label": "mistralai from\ne-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "mistralai from e-footprint hypothesis = mistralai", "x": 112.5, "y": 150}, {"color": "darkred", "id": "mistralai model used from e-footprint hypothesis", "label": "mistralai model used\nfrom e-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "mistralai model used from e-footprint hypothesis = open-mistral-7b", "x": 337.5, "y": 150}, {"color": "darkred", "id": "Base GPU latency per output_token from Ecologits", "label": "Base GPU latency per\noutput_token from\nEcologits", "shape": "dot", "size": 15, "title": "Base GPU latency per output_token from Ecologits = 0.019999999552965164 second", "x": 360.0, "y": 300}, {"color": null, "id": "Generative AI model job nb of required GPUs during inference", "label": "Generative AI model\njob nb of required\nGPUs during\ninference", "shape": "dot", "size": 15, "title": "Generative AI model job nb of required GPUs during inference\n=\nGenerative AI model ratio between GPU memory footprint and model size from\nEcologits * open-mistral-7b from mistralai nb of active parameters from\nEcologits * Generative AI model nb of bits per parameter from e-footprint\nhypothesis / on premise GPU server RAM per GPU from Estimating the Carbon\nFootprint of BLOOM\n=\n1.2000000476837158 dimensionless * 7299999744.0 dimensionless * 16.0\ndimensionless / 80.0 gigabyte / gpu\n=\n0.2199999988079071 gpu", "x": 337.5, "y": 750}, {"color": "darkred", "id": "Generative AI model ratio between GPU memory footprint and model size from Ecologits", "label": "Generative AI model\nratio between GPU\nmemory footprint and\nmodel size from\nEcologits", "shape": "dot", "size": 15, "title": "Generative AI model ratio between GPU memory footprint and model size from\nEcologits = 1.2000000476837158 dimensionless", "x": -75.0, "y": 600}, {"color": "darkred", "id": "Generative AI model nb of bits per parameter from e-footprint hypothesis", "label": "Generative AI model\nnb of bits per\nparameter from\ne-footprint\nhypothesis", "shape": "dot", "size": 15, "title": "Generative AI model nb of bits per parameter from e-footprint hypothesis = 16.0\ndimensionless", "x": 225.0, "y": 600}, {"color": "darkred", "id": "on premise GPU server RAM per GPU from Estimating the Carbon Footprint of BLOOM", "label": "on premise GPU\nserver RAM per GPU\nfrom Estimating the\nCarbon Footprint of\nBLOOM", "shape": "dot", "size": 15, "title": "on premise GPU server RAM per GPU from Estimating the Carbon Footprint of BLOOM\n= 80.0 gigabyte / gpu", "x": 375.0, "y": 600}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "Hourly Manually defined GPU job average occurrences across usage patterns", "to": "on premise GPU server hour by hour compute need"}, {"arrows": "to", "from": "Average hourly Manually defined GPU job occurrences in usage pattern", "to": "Hourly Manually defined GPU job average occurrences across usage patterns"}, {"arrows": "to", "from": "Hourly Manually defined GPU job occurrences in usage pattern", "to": "Average hourly Manually defined GPU job occurrences in usage pattern"}, {"arrows": "to", "from": "usage pattern UTC", "to": "Hourly Manually defined GPU job occurrences in usage pattern"}, {"arrows": "to", "from": "usage pattern hourly nb of visits from e-footprint hypothesis", "to": "usage pattern UTC"}, {"arrows": "to", "from": "devices country timezone from user data", "to": "usage pattern UTC"}, {"arrows": "to", "from": "Request duration of Manually defined GPU job from e-footprint hypothesis", "to": "Average hourly Manually defined GPU job occurrences in usage pattern"}, {"arrows": "to", "from": "gpus needed on server on premise GPU server to process Manually defined GPU job from e-footprint hypothesis", "to": "on premise GPU server hour by hour compute need"}, {"arrows": "to", "from": "Hourly Generative AI model job average occurrences across usage patterns", "to": "on premise GPU server hour by hour compute need"}, {"arrows": "to", "from": "Average hourly Generative AI model job occurrences in usage pattern", "to": "Hourly Generative AI model job average occurrences across usage patterns"}, {"arrows": "to", "from": "Hourly Generative AI model job occurrences in usage pattern", "to": "Average hourly Generative AI model job occurrences in usage pattern"}, {"arrows": "to", "from": "usage pattern UTC", "to": "Hourly Generative AI model job occurrences in usage pattern"}, {"arrows": "to", "from": "usage pattern hourly nb of visits from e-footprint hypothesis", "to": "usage pattern UTC"}, {"arrows": "to", "from": "devices country timezone from user data", "to": "usage pattern UTC"}, {"arrows": "to", "from": "Generative AI model job request duration", "to": "Average hourly Generative AI model job occurrences in usage pattern"}, {"arrows": "to", "from": "Generative AI model job output token count from e-footprint hypothesis", "to": "Generative AI model job request duration"}, {"arrows": "to", "from": "GPU latency per active parameter and output token from Ecologits", "to": "Generative AI model job request duration"}, {"arrows": "to", "from": "open-mistral-7b from mistralai nb of active parameters from Ecologits", "to": "Generative AI model job request duration"}, {"arrows": "to", "from": "mistralai from e-footprint hypothesis", "to": "open-mistral-7b from mistralai nb of active parameters from Ecologits"}, {"arrows": "to", "from": "mistralai model used from e-footprint hypothesis", "to": "open-mistral-7b from mistralai nb of active parameters from Ecologits"}, {"arrows": "to", "from": "Base GPU latency per output_token from Ecologits", "to": "Generative AI model job request duration"}, {"arrows": "to", "from": "Generative AI model job nb of required GPUs during inference", "to": "on premise GPU server hour by hour compute need"}, {"arrows": "to", "from": "Generative AI model ratio between GPU memory footprint and model size from Ecologits", "to": "Generative AI model job nb of required GPUs during inference"}, {"arrows": "to", "from": "open-mistral-7b from mistralai nb of active parameters from Ecologits", "to": "Generative AI model job nb of required GPUs during inference"}, {"arrows": "to", "from": "mistralai from e-footprint hypothesis", "to": "open-mistral-7b from mistralai nb of active parameters from Ecologits"}, {"arrows": "to", "from": "mistralai model used from e-footprint hypothesis", "to": "open-mistral-7b from mistralai nb of active parameters from Ecologits"}, {"arrows": "to", "from": "Generative AI model nb of bits per parameter from e-footprint hypothesis", "to": "Generative AI model job nb of required GPUs during inference"}, {"arrows": "to", "from": "on premise GPU server RAM per GPU from Estimating the Carbon Footprint of BLOOM", "to": "Generative AI model job nb of required GPUs during inference"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": false,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>